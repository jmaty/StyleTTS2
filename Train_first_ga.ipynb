{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fdd8cf1-70df-4961-afed-844af8813a41",
   "metadata": {},
   "source": [
    "# Imports & preparatory steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8e53c2-dbd2-40b3-aa5f-76fe1d366f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "import torch\n",
    "import shutil\n",
    "import yaml\n",
    "from torch import __version__ as torch_version\n",
    "from platform import python_version\n",
    "\n",
    "# Check CUDA is available\n",
    "assert torch.cuda.is_available(), \"CPU training is not allowed.\"\n",
    "\n",
    "# Check the number of CPUs\n",
    "# $PBS_NUM_PPN vs $OMP_NUM_THREADS?\n",
    "N_CPUS = int(os.environ[\"PBS_NUM_PPN\"])\n",
    "\n",
    "# Limit CPU operation in pytorch to `N_CPUS`\n",
    "torch.set_num_threads(N_CPUS)\n",
    "torch.set_num_interop_threads(N_CPUS)\n",
    "\n",
    "# Set username\n",
    "USER = os.environ[\"USER\"]\n",
    "\n",
    "n_gpus = torch.cuda.device_count()\n",
    "\n",
    "print(\" > Computational resources...\")\n",
    "print(f\" | > Number of CPUs: {N_CPUS}\")\n",
    "print(f\" | > Number of GPUs: {n_gpus}\")\n",
    "print(\" > Python & module versions...\")\n",
    "print(f\" | > Python:    {python_version()}\")\n",
    "print(f\" | > PyTorch:   {torch_version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b29b983-7dcd-4cdc-9577-c870bd9b4169",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952e8a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check interactive mode\n",
    "INTERACTIVE_MODE = bool(\"JupyterLab\" in os.environ[\"PBS_JOBNAME\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284b9f3d-cfc4-42b5-89c2-6009f44c3131",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "log_dir = \"Models/test\"\n",
    "first_stage_path = \"first_stage.pth\"\n",
    "save_freq = 2\n",
    "max_saved_models = 2\n",
    "log_interval = 10\n",
    "device = \"cuda\"\n",
    "epochs_1st = 200                    # number of epochs for first stage training (pre-training)\n",
    "epochs_2nd = 100                    # number of epochs for second stage training (joint training)\n",
    "batch_size = 6\n",
    "grad_accum_steps = 1                # JMa: gradient accumulation\n",
    "max_len = 300                       # maximum number of frames\n",
    "grad_clip = 5.0                     # JMa: gradient clipping\n",
    "pretrained_model = \"\"\n",
    "second_stage_load_pretrained = True # set to true if the pre-trained model is for 2nd stage\n",
    "load_only_params = False            # set to true if do not want to load epoch numbers and optimizer parameters\n",
    "\n",
    "F0_path = \"Utils/JDC/bst.t7\"\n",
    "ASR_config = \"Utils/ASR/config.yml\"\n",
    "ASR_path = \"Utils/ASR/epoch_00080.pth\"\n",
    "PLBERT_dir = 'Utils/PLBERT/'\n",
    "\n",
    "data_params = {\n",
    "    \"train_data\": \"/storage/plzen4-ntis/home/jmatouse/experimenty/StyleTTS2/Data/LJS/train100.csv\",\n",
    "    \"val_data\": \"/storage/plzen4-ntis/home/jmatouse/experimenty/StyleTTS2/Data/LJS/val.csv\",\n",
    "    \"root_path\": \"/storage/plzen4-ntis/home/jmatouse/experimenty/StyleTTS2/Data/LJS/wavs\",\n",
    "    \"OOD_data\": \"/storage/plzen4-ntis/home/jmatouse/experimenty/StyleTTS2/Data/LJS/OOD_texts.csv\",\n",
    "    \"min_length\": 50,  # sample until texts with this size are obtained for OOD texts\n",
    "    # test params\n",
    "    \"save_val_audio\": True,\n",
    "    \"save_test_audio\": False,\n",
    "    \"test_audio_dir\": \"test_audios\",  # directory under `log_dir`\n",
    "    \"test_sentences\": [\n",
    "        'pˈɜːsənəlˌaɪz ænd ˈɔːθɚ dˌiːvˌiːdˈiː wɪð tʃˈæptɚ mˈɛnjuː, sˈʌbtaɪɾəl, bˈækɡɹaʊnd mjˈuːzɪk ænd pˈɪktʃɚ.',\n",
    "        'ʌv kˈoːɹs bˈɑːksɪŋ ʃˌʊd biː ɛŋkˈɜːɹɪdʒd ɪnðɪ ˈɑːɹmi ænd nˈeɪvi.',\n",
    "        'jˈɛt ðɛɹ hɐvbɪn ænd stˈɪl ɑːɹ dʒˌiːoʊmɪtɹˈɪʃənz ænd fɪlˈɑːsəfɚz, ænd ˈiːvən sˌʌm ʌvðə mˈoʊst dɪstˈɪŋɡwɪʃt, hˌuː dˈaʊt wˈɛðɚ ðə hˈoʊl jˈuːnɪvˌɜːs, ɔːɹ tə spˈiːk mˈoːɹ wˈaɪdli ðə hˈoʊl ʌv bˈiːɪŋ, wʌz ˈoʊnli kɹiːˈeɪɾᵻd ɪn jˈuːklɪdz dʒiˈɑːmətɹi; ðeɪ ˈiːvən dˈɛɹ tə dɹˈiːm ðæt tˈuː pˈæɹəlˌɛl lˈaɪnz, wˌɪtʃ ɐkˈoːɹdɪŋ tə jˈuːklɪd kæn nˈɛvɚ mˈiːt ˌɔn ˈɜːθ, mˈeɪ mˈiːt sˈʌmwɛɹ ɪn ɪnfˈɪnᵻɾi.',\n",
    "  ],\n",
    "}\n",
    "\n",
    "preprocess_params = {\n",
    "    \"sr\": 24000,\n",
    "    \"spect_params\": {\n",
    "    \"n_fft\": 2048,\n",
    "    \"win_length\": 1200,\n",
    "    \"hop_length\": 300,\n",
    "    }\n",
    "}\n",
    "\n",
    "model_params = {\n",
    "    \"multispeaker\": False,\n",
    "    \"dim_in\": 64,\n",
    "    \"hidden_dim\": 512,\n",
    "    \"max_conv_dim\": 512,\n",
    "    \"n_layer\": 3,\n",
    "    \"n_mels\": 80,\n",
    "    \"n_token\": 178,   # number of phoneme tokens\n",
    "    \"max_dur\": 50,    # maximum duration of a single phoneme\n",
    "    \"style_dim\": 128, # style vector size\n",
    "    \"dropout\": 0.2,\n",
    "\n",
    "    # config for decoder\n",
    "    \"decoder\": {\n",
    "        \"type\": 'istftnet', # either hifigan or istftnet\n",
    "        \"resblock_kernel_sizes\": [3,7,11],\n",
    "        \"upsample_rates\":  [10, 6],\n",
    "        \"upsample_initial_channel\": 512,\n",
    "        \"resblock_dilation_sizes\": [[1,3,5], [1,3,5], [1,3,5]],\n",
    "        \"upsample_kernel_sizes\": [20, 12],\n",
    "        \"gen_istft_n_fft\": 20,\n",
    "        \"gen_istft_hop_size\": 5,\n",
    "    },\n",
    "      \n",
    "  # speech language model config\n",
    "    \"slm\": {\n",
    "        \"model\": 'microsoft/wavlm-base-plus',\n",
    "        \"sr\": 16000,                           # sampling rate of SLM\n",
    "        \"hidden\": 768,                         # hidden size of SLM\n",
    "        \"nlayers\": 13,                         # number of layers of SLM\n",
    "        \"initial_channel\": 64,                 # initial channels of SLM discriminator head\n",
    "    },\n",
    "  \n",
    "    # style diffusion model config\n",
    "    \"diffusion\": {\n",
    "        \"embedding_mask_proba\": 0.1,\n",
    "        # transformer config\n",
    "        \"transformer\": {\n",
    "            \"num_layers\": 3,\n",
    "            \"num_heads\": 8,\n",
    "            \"head_features\": 64,\n",
    "            \"multiplier\": 2,\n",
    "        },\n",
    "      # diffusion distribution config\n",
    "        \"dist\": {\n",
    "            \"sigma_data\": 0.2,            # placeholder for estimate_sigma_data set to false\n",
    "            \"estimate_sigma_data\": True,  # estimate sigma_data from the current batch if set to true\n",
    "            \"mean\": -3.0,\n",
    "            \"std\": 1.0,\n",
    "        }\n",
    "    }\n",
    "} \n",
    "\n",
    "loss_params = {\n",
    "    \"lambda_mel\": 5.,   # mel reconstruction loss\n",
    "    \"lambda_gen\": 1.,   # generator loss\n",
    "    \"lambda_slm\": 1.,   # slm feature matching loss\n",
    "    \"lambda_mono\": 1.,  # monotonic alignment loss (1st stage, TMA)\n",
    "    \"lambda_s2s\": 1.,   # sequence-to-sequence loss (1st stage, TMA)\n",
    "    \"TMA_epoch\": 5,    # TMA starting epoch (1st stage)\n",
    "    \"lambda_F0\": 1.,    # F0 reconstruction loss (2nd stage)\n",
    "    \"lambda_norm\": 1.,  # norm reconstruction loss (2nd stage)\n",
    "    \"lambda_dur\": 1.,   # duration loss (2nd stage)\n",
    "    \"lambda_ce\": 20.,   # duration predictor probability output CE loss (2nd stage)\n",
    "    \"lambda_sty\": 1.,   # style reconstruction loss (2nd stage)\n",
    "    \"lambda_diff\": 1.,  # score matching loss (2nd stage)\n",
    "    \"diff_epoch\": 20,   # style diffusion starting epoch (2nd stage)\n",
    "    \"joint_epoch\": 50,  # joint training starting epoch (2nd stage)\n",
    "}\n",
    "\n",
    "optimizer_params = {\n",
    "    \"lr\": 0.0001,         # general learning rate\n",
    "    \"bert_lr\": 0.00001,   # learning rate for PLBERT\n",
    "    \"ft_lr\": 0.00001,     # learning rate for acoustic modules\n",
    "}\n",
    "  \n",
    "slmadv_params = {\n",
    "    \"min_len\": 400,           # minimum length of samples\n",
    "    \"max_len\": 500,           # maximum length of samples\n",
    "    \"batch_percentage\": 0.5,  # to prevent out of memory, only use half of the original batch size\n",
    "    \"iter\": 10,               # update the discriminator every this iterations of generator update\n",
    "    \"thresh\": 5,              # gradient norm above which the gradient is scaled\n",
    "    \"scale\": 0.01,            # gradient scaling factor for predictors from SLM discriminators\n",
    "    \"sig\": 1.5,               # sigma for differentiable duration modeling\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65273fdc-b422-47d6-8358-f057a0a1a8a0",
   "metadata": {},
   "source": [
    "# Copy data to scratch dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075d5828-e730-4bd8-8ae3-9f6b5ba3f9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "scratch_dir = os.environ[\"SCRATCHDIR\"]\n",
    "if not INTERACTIVE_MODE:\n",
    "    # Copy dataset\n",
    "    # Prepare dataset dir in the scratch\n",
    "    print(f\"> Copying data to local scratch: {scratch_dir}\")\n",
    "    shutil.copy(data_params[\"train_data\"], scratch_dir, follow_symlinks=True)\n",
    "    shutil.copy(data_params[\"val_data\"], scratch_dir, follow_symlinks=True)\n",
    "    shutil.copy(data_params[\"OOD_data\"], scratch_dir, follow_symlinks=True)\n",
    "    # Copy wavs to local scratch if not exist\n",
    "    wav_dir = os.path.join(scratch_dir, \"wavs\")\n",
    "    shutil.copytree(data_params[\"root_path\"], wav_dir)\n",
    "    # Store the scratch dataset so that it is used for training\n",
    "    data_params[\"train_data\"] = os.path.join(scratch_dir, os.path.basename(data_params[\"train_data\"]))\n",
    "    data_params[\"val_data\"] = os.path.join(scratch_dir, os.path.basename(data_params[\"val_data\"]))\n",
    "    data_params[\"OOD_data\"] = os.path.join(scratch_dir, os.path.basename(data_params[\"OOD_data\"]))\n",
    "    data_params[\"root_path\"] = wav_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3393009",
   "metadata": {},
   "source": [
    "# Create/update config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8976fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"log_dir\": log_dir,\n",
    "    \"first_stage_path\": first_stage_path,\n",
    "    \"save_freq\": save_freq,\n",
    "    \"max_saved_models\": max_saved_models,\n",
    "    \"log_interval\": log_interval,\n",
    "    \"device\": device,\n",
    "    \"epochs_1st\": epochs_1st,\n",
    "    \"epochs_2nd\": epochs_2nd,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"grad_accum_steps\": grad_accum_steps,\n",
    "    \"max_len\": max_len,\n",
    "    \"grad_clip\": grad_clip,\n",
    "    \"pretrained_model\": pretrained_model,\n",
    "    \"second_stage_load_pretrained\": second_stage_load_pretrained,\n",
    "    \"load_only_params\": load_only_params,\n",
    "    \"F0_path\": F0_path,\n",
    "    \"ASR_config\": ASR_config,\n",
    "    \"ASR_path\": ASR_path,\n",
    "    \"PLBERT_dir\": PLBERT_dir,\n",
    "    \"data_params\": data_params,\n",
    "    \"preprocess_params\": preprocess_params,\n",
    "    \"model_params\": model_params,\n",
    "    \"loss_params\": loss_params,\n",
    "    \"optimizer_params\": optimizer_params,\n",
    "    \"slmadv_params\": slmadv_params\n",
    "}\n",
    "\n",
    "config_file = os.path.join(scratch_dir, \"config.yml\")\n",
    "# Write to a YAML file\n",
    "with open(config_file, 'w') as file:\n",
    "    yaml.dump(config, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3511b4d5",
   "metadata": {},
   "source": [
    "## Run training script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9419b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run train_first.py --config_path {config_file}\n",
    "# !accelerate launch --mixed_precision=no train_first.py --config_path {config_file}\n",
    "# !python train_first.py --config_path {config_file}\n",
    "print(\" > Start training...\")\n",
    "print(f\" | > Batch size: {batch_size}\")\n",
    "print(f\" | > Max len: {max_len}\")\n",
    "\n",
    "!accelerate launch --mixed_precision=no train_first_fix-ga2.py --config_path {config_file}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ddb788-d61f-4dfe-acc9-66c6546feb3f",
   "metadata": {},
   "source": [
    "# Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873a8a1c-59ee-41e0-8d15-bcf7dbe905a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not INTERACTIVE_MODE:\n",
    "    # Delete all files and subdirectories in the directory\n",
    "    for filename in os.listdir(scratch_dir):\n",
    "        file_path = os.path.join(scratch_dir, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)  # remove file or symlink\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)  # remove directory\n",
    "        except Exception as e:\n",
    "            print(f'Failed to delete {file_path}. Reason: {e}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
