{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fdd8cf1-70df-4961-afed-844af8813a41",
   "metadata": {},
   "source": [
    "# Imports & preparatory steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a8e53c2-dbd2-40b3-aa5f-76fe1d366f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Computational resources...\n",
      " | > Number of CPUs: 1\n",
      " | > Number of GPUs: 1\n",
      " > Python & module versions...\n",
      " | > Python:    3.10.12\n",
      " | > PyTorch:   2.1.2+cu121\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import os.path\n",
    "import torch\n",
    "import shutil\n",
    "import yaml\n",
    "from torch import __version__ as torch_version\n",
    "from platform import python_version\n",
    "\n",
    "# Check CUDA is available\n",
    "assert torch.cuda.is_available(), \"CPU training is not allowed.\"\n",
    "\n",
    "# Check the number of CPUs\n",
    "# $PBS_NUM_PPN vs $OMP_NUM_THREADS?\n",
    "N_CPUS = int(os.environ[\"PBS_NUM_PPN\"])\n",
    "\n",
    "# Limit CPU operation in pytorch to `N_CPUS`\n",
    "torch.set_num_threads(N_CPUS)\n",
    "torch.set_num_interop_threads(N_CPUS)\n",
    "\n",
    "# Set username\n",
    "USER = os.environ[\"USER\"]\n",
    "\n",
    "n_gpus = torch.cuda.device_count()\n",
    "\n",
    "print(\" > Computational resources...\")\n",
    "print(f\" | > Number of CPUs: {N_CPUS}\")\n",
    "print(f\" | > Number of GPUs: {n_gpus}\")\n",
    "print(\" > Python & module versions...\")\n",
    "print(f\" | > Python:    {python_version()}\")\n",
    "print(f\" | > PyTorch:   {torch_version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b29b983-7dcd-4cdc-9577-c870bd9b4169",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "952e8a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-Coqui-TTS parameters\n",
    "COPY_TO_SCRATCH = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "284b9f3d-cfc4-42b5-89c2-6009f44c3131",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "run_name = \"pokus\"\n",
    "log_dir = \"Models/LJS_ft-LibriTTS\"\n",
    "save_freq = 5\n",
    "log_interval = 10\n",
    "device = \"cuda\"\n",
    "epochs = 50 # number of finetuning epoch (1 hour of data)\n",
    "batch_size = 8\n",
    "max_len: 400 # maximum number of frames\n",
    "pretrained_model = \"Models/LibriTTS/epochs_2nd_00020.pth\"\n",
    "second_stage_load_pretrained = True # set to true if the pre-trained model is for 2nd stage\n",
    "load_only_params = True # set to true if do not want to load epoch numbers and optimizer parameters\n",
    "\n",
    "F0_path = \"Utils/JDC/bst.t7\"\n",
    "ASR_config = \"Utils/ASR/config.yml\"\n",
    "ASR_path = \"Utils/ASR/epoch_00080.pth\"\n",
    "PLBERT_dir = 'Utils/PLBERT/'\n",
    "\n",
    "data_params = {\n",
    "  \"train_data\": \"Data/train_list.txt\",\n",
    "  \"val_data\": \"Data/val_list.txt\",\n",
    "  \"root_path\": \"/local/LJSpeech-1.1/wavs\",\n",
    "  \"OOD_data\": \"Data/OOD_texts.txt\",\n",
    "  \"min_length\": 50 # sample until texts with this size are obtained for OOD texts\n",
    "}\n",
    "\n",
    "preprocess_params = {\n",
    "   \"sr\": 24000,\n",
    "   \"spect_params\": {\n",
    "      \"n_fft\": 2048,\n",
    "      \"win_length\": 1200,\n",
    "      \"hop_length\": 300,\n",
    "  }\n",
    "}\n",
    "\n",
    "model_params = {\n",
    "  \"multispeaker\": True,\n",
    "  \"dim_in\": 64,\n",
    "  \"hidden_dim\": 512,\n",
    "  \"max_conv_dim\": 512,\n",
    "  \"n_layer\": 3,\n",
    "  \"n_mels\": 80,\n",
    "  \"n_token\": 178, # number of phoneme tokens\n",
    "  \"max_dur\": 50, # maximum duration of a single phoneme\n",
    "  \"style_dim\": 128, # style vector size\n",
    "  \"dropout\": 0.2,\n",
    "\n",
    "  # config for decoder\n",
    "  \"decoder\": { \n",
    "      \"type\": 'hifigan', # either hifigan or istftnet\n",
    "      \"resblock_kernel_sizes\": [3,7,11],\n",
    "      \"upsample_rates\" :  [10,5,3,2],\n",
    "      \"upsample_initial_channel\": 512,\n",
    "      \"resblock_dilation_sizes\": [[1,3,5], [1,3,5], [1,3,5]],\n",
    "      \"upsample_kernel_sizes\": [20,10,6,4],\n",
    "  },\n",
    "\n",
    "  # speech language model config\n",
    "  \"slm\": {\n",
    "      \"model\": 'microsoft/wavlm-base-plus',\n",
    "      \"sr\": 16000, # sampling rate of SLM\n",
    "      \"hidden\": 768, # hidden size of SLM\n",
    "      \"nlayers\": 13, # number of layers of SLM\n",
    "      \"initial_channel\": 64, # initial channels of SLM discriminator head\n",
    "  },\n",
    "\n",
    "  # style diffusion model config\n",
    "  \"diffusion\": {\n",
    "    \"embedding_mask_proba\": 0.1,\n",
    "    # transformer config\n",
    "    \"transformer\": {\n",
    "      \"num_layers\": 3,\n",
    "      \"num_heads\": 8,\n",
    "      \"head_features\": 64,\n",
    "      \"multiplier\": 2,\n",
    "    },\n",
    "    # diffusion distribution config\n",
    "    \"dist\": {\n",
    "      \"sigma_data\": 0.2, # placeholder for estimate_sigma_data set to false\n",
    "      \"estimate_sigma_data\": True, # estimate sigma_data from the current batch if set to true\n",
    "      \"mean\": -3.0,\n",
    "      \"std\": 1.0,\n",
    "    }\n",
    "  }\n",
    "}\n",
    "  \n",
    "loss_params = {\n",
    "    \"lambda_mel\": 5.,   # mel reconstruction loss\n",
    "    \"lambda_gen\": 1.,   # generator loss\n",
    "    \"lambda_slm\": 1.,   # slm feature matching loss\n",
    "    \n",
    "    \"lambda_mono\": 1.,  # monotonic alignment loss (TMA)\n",
    "    \"lambda_s2s\": 1.,   # sequence-to-sequence loss (TMA)\n",
    "\n",
    "    \"lambda_F0\": 1.,    # F0 reconstruction loss\n",
    "    \"lambda_norm\": 1.,  # norm reconstruction loss\n",
    "    \"lambda_dur\": 1.,   # duration loss\n",
    "    \"lambda_ce\": 20.,   # duration predictor probability output CE loss\n",
    "    \"lambda_sty\": 1.,   # style reconstruction loss\n",
    "    \"lambda_diff\": 1.,  # score matching loss\n",
    "    \n",
    "    \"diff_epoch\": 10,   # style diffusion starting epoch\n",
    "    \"joint_epoch\": 30,  # joint training starting epoch\n",
    "}\n",
    "\n",
    "optimizer_params = {\n",
    "  \"lr\": 0.0001, # general learning rate\n",
    "  \"bert_lr\": 0.00001, # learning rate for PLBERT\n",
    "  \"ft_lr\": 0.0001, # learning rate for acoustic modules\n",
    "}\n",
    "  \n",
    "slmadv_params = {\n",
    "  \"min_len\": 400, # minimum length of samples\n",
    "  \"max_len\": 500, # maximum length of samples\n",
    "  \"batch_percentage\": 0.5, # to prevent out of memory, only use half of the original batch size\n",
    "  \"iter\": 10, # update the discriminator every this iterations of generator update\n",
    "  \"thresh\": 5, # gradient norm above which the gradient is scaled\n",
    "  \"scale\": 0.01, # gradient scaling factor for predictors from SLM discriminators\n",
    "  \"sig\": 1.5, # sigma for differentiable duration modeling\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0b8b0f2-629c-4d7f-be92-18ab310a4015",
   "metadata": {
    "tags": [
     "injected_parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "# Non-Coqui-TTS parameters\n",
    "COPY_TO_SCRATCH = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65273fdc-b422-47d6-8358-f057a0a1a8a0",
   "metadata": {},
   "source": [
    "# Copy data to scratch dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "075d5828-e730-4bd8-8ae3-9f6b5ba3f9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "scratch_dir = os.environ[\"SCRATCHDIR\"]\n",
    "if COPY_TO_SCRATCH:\n",
    "    # Copy dataset\n",
    "    # Prepare dataset dir in the scratch\n",
    "    print(f\"> Copying data to local scratch: {scratch_dir}\")\n",
    "    shutil.copy(data_params[\"train_data\"], scratch_dir, follow_symlinks=True)\n",
    "    shutil.copy(data_params[\"val_data\"], scratch_dir, follow_symlinks=True)\n",
    "    shutil.copy(data_params[\"OOD_data\"], scratch_dir, follow_symlinks=True)\n",
    "    # Copy wavs to local scratch if not exist\n",
    "    wav_dir = os.path.join(scratch_dir, \"wavs\")\n",
    "    # if not os.path.isfile(wav_dir):\n",
    "        # shutil.copy(data_params[\"root_path\"], wav_dir, follow_symlinks=True)\n",
    "    shutil.copytree(data_params[\"root_path\"], wav_dir)\n",
    "    # Store the scratch dataset so that it is used for training\n",
    "    data_params[\"train_data\"] = os.path.join(scratch_dir, os.path.basename(data_params[\"train_data\"]))\n",
    "    data_params[\"val_data\"] = os.path.join(scratch_dir, os.path.basename(data_params[\"val_data\"]))\n",
    "    data_params[\"OOD_data\"] = os.path.join(scratch_dir, os.path.basename(data_params[\"OOD_data\"]))\n",
    "    data_params[\"root_path\"] = wav_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3393009",
   "metadata": {},
   "source": [
    "# Create/update config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8976fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"log_dir\": log_dir,\n",
    "    \"save_freq\": save_freq,\n",
    "    \"log_interval\": log_interval,\n",
    "    \"device\": device,\n",
    "    \"epochs\": epochs,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"max_len\": max_len,\n",
    "    \"pretrained_model\": pretrained_model,\n",
    "    \"second_stage_load_pretrained\": second_stage_load_pretrained,\n",
    "    \"load_only_params\": load_only_params,\n",
    "    \"F0_path\": F0_path,\n",
    "    \"ASR_config\": ASR_config,\n",
    "    \"ASR_path\": ASR_path,\n",
    "    \"PLBERT_dir\": PLBERT_dir,\n",
    "    \"data_params\": data_params,\n",
    "    \"preprocess_params\": preprocess_params,\n",
    "    \"model_params\": model_params,\n",
    "    \"loss_params\": loss_params,\n",
    "    \"optimizer_params\": optimizer_params,\n",
    "    \"slmadv_params\": slmadv_params\n",
    "}\n",
    "\n",
    "config_file = os.path.join(scratch_dir, \"config.yml\")\n",
    "# Write to a YAML file\n",
    "with open(config_file, 'w') as file:\n",
    "    yaml.dump(config, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3511b4d5",
   "metadata": {},
   "source": [
    "## Run training script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9419b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python train_finetune.py --config_path {config_file}\n",
    "!accelerate launch --mixed_precision=fp16 --num_processes=1 train_finetune_accelerate.py --config_path {config_file}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ddb788-d61f-4dfe-acc9-66c6546feb3f",
   "metadata": {},
   "source": [
    "# Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873a8a1c-59ee-41e0-8d15-bcf7dbe905a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if COPY_TO_SCRATCH:\n",
    "    # Delete all files and subdirectories in the directory\n",
    "    for filename in os.listdir(scratch_dir):\n",
    "        file_path = os.path.join(scratch_dir, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)  # remove file or symlink\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)  # remove directory\n",
    "        except Exception as e:\n",
    "            print(f'Failed to delete {file_path}. Reason: {e}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
